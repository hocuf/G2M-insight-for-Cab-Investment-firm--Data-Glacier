{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03270546",
   "metadata": {},
   "source": [
    "# Week 6: File ingestion and schema validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c165251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask pyarrow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75090f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "502c2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c49889",
   "metadata": {},
   "source": [
    "#### File made to 2GB+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f185ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = pd.concat([df]*2)\n",
    "df_big.to_csv('weather_big.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103dfcdb",
   "metadata": {},
   "source": [
    "## With Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "619ff574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Read Time: 240.62841486930847 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_pandas = pd.read_csv('weather_big.csv')\n",
    "print(f\"Pandas Read Time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59a1c5",
   "metadata": {},
   "source": [
    "## With Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfcae1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\backends.py\", line 136, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 761, in read\n",
      "    return read_pandas(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 658, in read_pandas\n",
      "    return text_blocks_to_pandas(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\io\\csv.py\", line 393, in text_blocks_to_pandas\n",
      "    return from_map(\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\io\\io.py\", line 1081, in from_map\n",
      "    return new_dd_object(graph, name, meta, divisions)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 8219, in new_dd_object\n",
      "    return get_parallel_type(meta)(dsk, name, meta, divisions)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 4776, in __init__\n",
      "    super().__init__(dsk, name, meta, divisions)\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\core.py\", line 423, in __init__\n",
      "    is_object_string_dataframe(meta)\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\_pyarrow.py\", line 59, in is_object_string_dataframe\n",
      "    any(is_object_string_series(s) for _, s in x.items())\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\_pyarrow.py\", line 59, in <genexpr>\n",
      "    any(is_object_string_series(s) for _, s in x.items())\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\_pyarrow.py\", line 53, in is_object_string_series\n",
      "    is_object_string_dtype(x.dtype) or is_object_string_index(x.index)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\_pyarrow.py\", line 34, in is_object_string_dtype\n",
      "    and not is_pyarrow_string_dtype(dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\dataframe\\_pyarrow.py\", line 23, in is_pyarrow_string_dtype\n",
      "    pa_string_types = [pd.StringDtype(\"pyarrow\"), pd.ArrowDtype(pa.string())]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\pandas\\core\\arrays\\string_.py\", line 125, in __init__\n",
      "    raise ImportError(\n",
      "ImportError: pyarrow>=7.0.0 is required for PyArrow backed StringArray.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_2360\\2010595414.py\", line 2, in <module>\n",
      "    df_dask = dd.read_csv('weather_big.csv')\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\dask\\backends.py\", line 138, in wrapper\n",
      "    raise type(e)(\n",
      "ImportError: An error occurred while calling the read_csv method registered to the pandas backend.\n",
      "Original Message: pyarrow>=7.0.0 is required for PyArrow backed StringArray.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1159, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\abdul\\anaconda3\\envs\\NLP\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df_dask = dd.read_csv('weather_big.csv')\n",
    "print(f\"Dask Read Time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05b0330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0.0\n"
     ]
    }
   ],
   "source": [
    "import pyarrow\n",
    "print(pyarrow.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7997701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (2023.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (2.0.3)\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/b7/f8/32d6b5aa4c4bc045fa2c4c58f88c325facc54721956c6313f0afea8ea853/pandas-2.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pandas-2.1.0-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (2023.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (23.1)\n",
      "Requirement already satisfied: partd>=1.2.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (1.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from dask) (6.8.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from click>=8.0->dask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from importlib-metadata>=4.13.0->dask) (3.16.2)\n",
      "Requirement already satisfied: locket in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from partd>=1.2.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.1.0-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "Successfully installed pandas-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modin 0.23.1 requires pandas<2.1,>=2, but you have pandas 2.1.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade dask pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814cd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
